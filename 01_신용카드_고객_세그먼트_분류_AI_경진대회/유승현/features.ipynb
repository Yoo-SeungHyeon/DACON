{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas numpy scikit-learn xgboost pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (Reading Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# train_df = pd.read_csv(\"../data/all_train.csv\")\n",
    "# test_df = pd.read_csv(\"../data/all_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Segment í¬í•¨ëœ train_dfë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬\n",
    "# train_df = train_df.iloc[:, 1:]\n",
    "# for col in train_df.columns:\n",
    "#     if train_df[col].isnull().any():\n",
    "#         train_df[col].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# # Feature / Label ë¶„ë¦¬\n",
    "# y = train_df[\"Segment\"]\n",
    "# X = train_df.drop(columns=[\"Segment\"]).select_dtypes(exclude=['object'])\n",
    "\n",
    "# # Label ì¸ì½”ë”©\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# # ìŠ¤ì¼€ì¼ë§\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # Train/Test ë¶„í• \n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_scaled, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# models = [\n",
    "#     (\"LogisticRegression\", LogisticRegression(max_iter=1000)),\n",
    "#     (\"RandomForest (depth=5)\", RandomForestClassifier(max_depth=5, n_estimators=100, random_state=42)),\n",
    "#     (\"RandomForest (depth=10)\", RandomForestClassifier(max_depth=10, n_estimators=100, random_state=42)),\n",
    "#     (\"XGBoost (depth=3)\", XGBClassifier(max_depth=3, use_label_encoder=False, eval_metric='mlogloss')),\n",
    "#     (\"XGBoost (depth=6)\", XGBClassifier(max_depth=6, use_label_encoder=False, eval_metric='mlogloss')),\n",
    "#     (\"LGBM (depth=3)\", LGBMClassifier(max_depth=3)),\n",
    "#     (\"LGBM (depth=6)\", LGBMClassifier(max_depth=6)),\n",
    "#     (\"GradientBoosting\", GradientBoostingClassifier(max_depth=4, n_estimators=100))\n",
    "# ]\n",
    "\n",
    "# # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "# results = []\n",
    "\n",
    "# for name, model in models:\n",
    "#     print(f\"\\nğŸ” ëª¨ë¸: {name}\")\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     elapsed_time = time.time() - start_time\n",
    "    \n",
    "#     f1 = f1_score(y_test, y_pred, average='macro')\n",
    "#     print(f\"ğŸ§® F1_macro score: {f1:.4f}\")\n",
    "    \n",
    "#     # ì €ì¥\n",
    "#     results.append({\n",
    "#         \"Model\": name,\n",
    "#         \"F1_macro\": f1,\n",
    "#         \"Time(s)\": round(elapsed_time, 2)\n",
    "#     })\n",
    "\n",
    "#     # ìƒì„¸ ë¦¬í¬íŠ¸ë„ ì›í•˜ë©´ ì¶œë ¥ ê°€ëŠ¥\n",
    "#     print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df = results_df.sort_values(by=\"F1_macro\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# # ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\n",
    "# from IPython.display import display\n",
    "# display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Depth ë¹„êµë¥¼ í†µí•œ ìµœì í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SSAFY\\AppData\\Local\\Temp\\ipykernel_17696\\427125886.py:3: DtypeWarning: Columns (300,385) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(\"../data/all_train.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"../data/all_train.csv\")\n",
    "# test_df = pd.read_csv(\"../data/all_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SSAFY\\AppData\\Local\\Temp\\ipykernel_17696\\305744020.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[col].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Segment í¬í•¨ëœ train_dfë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬\n",
    "train_df = train_df.iloc[:, 1:]\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].isnull().any():\n",
    "        train_df[col].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Feature / Label ë¶„ë¦¬\n",
    "y = train_df[\"Segment\"]\n",
    "X = train_df.drop(columns=[\"Segment\"]).select_dtypes(exclude=['object'])\n",
    "\n",
    "# Label ì¸ì½”ë”©\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• Featureì™€ Labelì„ í¬í•¨í•œ ë°ì´í„° ì €ì¥\n",
    "numeric_df = pd.concat([pd.DataFrame(X, columns=train_df.drop(columns=[\"Segment\"]).select_dtypes(exclude=['object']).columns), train_df[\"Segment\"].reset_index(drop=True)], axis=1)\n",
    "numeric_df.to_csv(\"../data/numeric_train.csv\", index=False)\n",
    "\n",
    "\n",
    "# Train/Test ë¶„í• \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric ë°ì´í„°ë§Œ ë”°ë¡œ ë¶ˆëŸ¬ì™€ì„œ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numeric_df = pd.read_csv(\"../data/numeric_train.csv\")\n",
    "\n",
    "# Feature / Label ë¶„ë¦¬\n",
    "y = numeric_df[\"Segment\"]\n",
    "X = numeric_df.drop(columns=[\"Segment\"])\n",
    "\n",
    "# Label ì¸ì½”ë”©\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, stratify=y_encoded, random_state=8432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400000 entries, 0 to 2399999\n",
      "Columns: 809 entries, ê¸°ì¤€ë…„ì›” to Segment\n",
      "dtypes: float64(61), int64(747), object(1)\n",
      "memory usage: 14.5+ GB\n"
     ]
    }
   ],
   "source": [
    "numeric_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400000 entries, 0 to 2399999\n",
      "Columns: 808 entries, ê¸°ì¤€ë…„ì›” to í˜œíƒìˆ˜í˜œìœ¨_B0M\n",
      "dtypes: float64(61), int64(747)\n",
      "memory usage: 14.4 GB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  depthë§Œ ë³€í™”ë¥¼ ì£¼ë©´ì„œ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ² XGBoost max_depth=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:55:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” F1_macro score: 0.7870\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.95      0.62      0.75       194\n",
      "           B       1.00      0.59      0.74        29\n",
      "           C       0.78      0.69      0.73     25518\n",
      "           D       0.77      0.72      0.75     69848\n",
      "           E       0.96      0.97      0.96    384411\n",
      "\n",
      "    accuracy                           0.92    480000\n",
      "   macro avg       0.89      0.72      0.79    480000\n",
      "weighted avg       0.92      0.92      0.92    480000\n",
      "\n",
      "â± í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œê°„: 353.59ì´ˆ\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: xgboost_depth6_f10.7870.joblib\n",
      "\n",
      "ğŸŒ² XGBoost max_depth=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:00:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” F1_macro score: 0.8020\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.65      0.78       194\n",
      "           B       1.00      0.59      0.74        29\n",
      "           C       0.80      0.72      0.76     25518\n",
      "           D       0.79      0.75      0.77     69848\n",
      "           E       0.96      0.98      0.97    384411\n",
      "\n",
      "    accuracy                           0.93    480000\n",
      "   macro avg       0.91      0.73      0.80    480000\n",
      "weighted avg       0.93      0.93      0.93    480000\n",
      "\n",
      "â± í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œê°„: 314.54ì´ˆ\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: xgboost_depth7_f10.8020.joblib\n",
      "\n",
      "ğŸŒ² XGBoost max_depth=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:05:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” F1_macro score: 0.8065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.65      0.78       194\n",
      "           B       1.00      0.55      0.71        29\n",
      "           C       0.83      0.74      0.78     25518\n",
      "           D       0.81      0.77      0.79     69848\n",
      "           E       0.96      0.98      0.97    384411\n",
      "\n",
      "    accuracy                           0.94    480000\n",
      "   macro avg       0.91      0.74      0.81    480000\n",
      "weighted avg       0.93      0.94      0.93    480000\n",
      "\n",
      "â± í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œê°„: 343.26ì´ˆ\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: xgboost_depth8_f10.8065.joblib\n",
      "\n",
      "ğŸŒ² XGBoost max_depth=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:11:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” F1_macro score: 0.8074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.96      0.63      0.76       194\n",
      "           B       1.00      0.52      0.68        29\n",
      "           C       0.85      0.77      0.81     25518\n",
      "           D       0.83      0.80      0.81     69848\n",
      "           E       0.97      0.98      0.97    384411\n",
      "\n",
      "    accuracy                           0.94    480000\n",
      "   macro avg       0.92      0.74      0.81    480000\n",
      "weighted avg       0.94      0.94      0.94    480000\n",
      "\n",
      "â± í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œê°„: 366.08ì´ˆ\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: xgboost_depth9_f10.8074.joblib\n",
      "\n",
      "ğŸŒ² XGBoost max_depth=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:17:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” F1_macro score: 0.8205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.95      0.65      0.78       194\n",
      "           B       1.00      0.52      0.68        29\n",
      "           C       0.88      0.79      0.83     25518\n",
      "           D       0.85      0.82      0.83     69848\n",
      "           E       0.97      0.98      0.98    384411\n",
      "\n",
      "    accuracy                           0.95    480000\n",
      "   macro avg       0.93      0.75      0.82    480000\n",
      "weighted avg       0.95      0.95      0.95    480000\n",
      "\n",
      "â± í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œê°„: 399.22ì´ˆ\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: xgboost_depth10_f10.8205.joblib\n",
      "\n",
      "ğŸŒ² XGBoost max_depth=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:23:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” F1_macro score: 0.8197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.64      0.77       194\n",
      "           B       1.00      0.48      0.65        29\n",
      "           C       0.89      0.81      0.85     25518\n",
      "           D       0.87      0.84      0.85     69848\n",
      "           E       0.97      0.98      0.98    384411\n",
      "\n",
      "    accuracy                           0.95    480000\n",
      "   macro avg       0.94      0.75      0.82    480000\n",
      "weighted avg       0.95      0.95      0.95    480000\n",
      "\n",
      "â± í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œê°„: 446.49ì´ˆ\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: xgboost_depth11_f10.8197.joblib\n",
      "\n",
      "ğŸŒ² XGBoost max_depth=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:31:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” F1_macro score: 0.8094\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.63      0.76       194\n",
      "           B       1.00      0.41      0.59        29\n",
      "           C       0.90      0.81      0.86     25518\n",
      "           D       0.88      0.85      0.86     69848\n",
      "           E       0.97      0.99      0.98    384411\n",
      "\n",
      "    accuracy                           0.96    480000\n",
      "   macro avg       0.95      0.74      0.81    480000\n",
      "weighted avg       0.96      0.96      0.96    480000\n",
      "\n",
      "â± í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œê°„: 503.62ì´ˆ\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: xgboost_depth12_f10.8094.joblib\n",
      "\n",
      "ğŸŒ² XGBoost max_depth=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:39:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” F1_macro score: 0.8206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.94      0.61      0.74       194\n",
      "           B       1.00      0.48      0.65        29\n",
      "           C       0.91      0.81      0.86     25518\n",
      "           D       0.89      0.85      0.87     69848\n",
      "           E       0.97      0.99      0.98    384411\n",
      "\n",
      "    accuracy                           0.96    480000\n",
      "   macro avg       0.94      0.75      0.82    480000\n",
      "weighted avg       0.96      0.96      0.96    480000\n",
      "\n",
      "â± í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œê°„: 582.62ì´ˆ\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: xgboost_depth13_f10.8206.joblib\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import joblib\n",
    "import gc\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "depth_values = [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "\n",
    "for depth in depth_values:\n",
    "    print(f\"\\nğŸŒ² XGBoost max_depth={depth}\") \n",
    "    model = XGBClassifier(max_depth=depth, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"ğŸ” F1_macro score: {f1:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "    print(f\"â± í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œê°„: {elapsed_time:.2f}ì´ˆ\")\n",
    "\n",
    "    # ëª¨ë¸ ì €ì¥ (íŒŒì¼ëª…ì— max_depthì™€ f1 score í¬í•¨)\n",
    "    model_filename = f\"xgboost_depth{depth}_f1{f1:.4f}.joblib\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_filename}\")\n",
    "\n",
    "    # ë©”ëª¨ë¦¬ í•´ì œë¥¼ ìœ„í•´ ëª¨ë¸ ë³€ìˆ˜ ì‚­ì œ ë° ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìˆ˜í–‰\n",
    "    del model\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ² XGBoost max_depth=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\.venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:36:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” F1_macro score: 0.7821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.65      0.78       194\n",
      "           B       1.00      0.52      0.68        29\n",
      "           C       0.78      0.69      0.74     25518\n",
      "           D       0.77      0.72      0.75     69848\n",
      "           E       0.96      0.97      0.96    384411\n",
      "\n",
      "    accuracy                           0.92    480000\n",
      "   macro avg       0.90      0.71      0.78    480000\n",
      "weighted avg       0.92      0.92      0.92    480000\n",
      "\n",
      "\n",
      "ğŸŒ² XGBoost max_depth=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\.venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:41:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” F1_macro score: 0.8063\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.68      0.80       194\n",
      "           B       1.00      0.59      0.74        29\n",
      "           C       0.80      0.72      0.76     25518\n",
      "           D       0.79      0.75      0.77     69848\n",
      "           E       0.96      0.98      0.97    384411\n",
      "\n",
      "    accuracy                           0.93    480000\n",
      "   macro avg       0.90      0.74      0.81    480000\n",
      "weighted avg       0.93      0.93      0.93    480000\n",
      "\n",
      "\n",
      "ğŸŒ² XGBoost max_depth=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\.venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:46:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” F1_macro score: 0.7909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.66      0.79       194\n",
      "           B       1.00      0.45      0.62        29\n",
      "           C       0.83      0.75      0.78     25518\n",
      "           D       0.81      0.77      0.79     69848\n",
      "           E       0.96      0.98      0.97    384411\n",
      "\n",
      "    accuracy                           0.94    480000\n",
      "   macro avg       0.92      0.72      0.79    480000\n",
      "weighted avg       0.93      0.94      0.93    480000\n",
      "\n",
      "\n",
      "ğŸŒ² XGBoost max_depth=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\.venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:52:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” F1_macro score: 0.8137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.66      0.79       194\n",
      "           B       1.00      0.52      0.68        29\n",
      "           C       0.85      0.77      0.81     25518\n",
      "           D       0.83      0.79      0.81     69848\n",
      "           E       0.97      0.98      0.97    384411\n",
      "\n",
      "    accuracy                           0.94    480000\n",
      "   macro avg       0.93      0.75      0.81    480000\n",
      "weighted avg       0.94      0.94      0.94    480000\n",
      "\n",
      "\n",
      "ğŸŒ² XGBoost max_depth=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\.venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:58:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from IPython.display import display\n",
    "\n",
    "depth_values = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "xgb_results = []    \n",
    "best_model = None\n",
    "best_f1 = 0\n",
    "best_depth = None\n",
    "\n",
    "for depth in depth_values:\n",
    "    print(f\"\\nğŸŒ² XGBoost max_depth={depth}\") \n",
    "    model = XGBClassifier(max_depth=depth, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"ğŸ” F1_macro score: {f1:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "    xgb_results.append({\n",
    "        \"max_depth\": depth,\n",
    "        \"F1_macro\": f1,\n",
    "        \"Time(s)\": round(elapsed_time, 2)\n",
    "    })\n",
    "\n",
    "    # ê°€ì¥ ì„±ëŠ¥ ì¢‹ì€ ëª¨ë¸ ì €ì¥\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = model\n",
    "        best_depth = depth\n",
    "\n",
    "# ê²°ê³¼ ì •ë¦¬\n",
    "xgb_results_df = pd.DataFrame(xgb_results).sort_values(by=\"F1_macro\", ascending=False).reset_index(drop=True)\n",
    "display(xgb_results_df)\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥\n",
    "model_filename = f\"best_xgboost_depth{best_depth}_f1{best_f1:.4f}.joblib\"\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"\\nğŸ’¾ Best XGBoost ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ëª¨ë“  í–‰ê³¼ ì—´, ê·¸ë¦¬ê³  ê° ì…€ì˜ ë‚´ìš©ì„ ìƒëµ ì—†ì´ ì¶œë ¥í•˜ë„ë¡ ì„¤ì •\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ê¸°ì¤€ë…„ì›”</th>\n",
       "      <th>ë‚¨ë…€êµ¬ë¶„ì½”ë“œ</th>\n",
       "      <th>íšŒì›ì—¬ë¶€_ì´ìš©ê°€ëŠ¥</th>\n",
       "      <th>íšŒì›ì—¬ë¶€_ì´ìš©ê°€ëŠ¥_CA</th>\n",
       "      <th>íšŒì›ì—¬ë¶€_ì´ìš©ê°€ëŠ¥_ì¹´ë“œë¡ </th>\n",
       "      <th>ì†Œì§€ì—¬ë¶€_ì‹ ìš©</th>\n",
       "      <th>ì†Œì§€ì¹´ë“œìˆ˜_ìœ íš¨_ì‹ ìš©</th>\n",
       "      <th>ì†Œì§€ì¹´ë“œìˆ˜_ì´ìš©ê°€ëŠ¥_ì‹ ìš©</th>\n",
       "      <th>ì…íšŒì¼ì_ì‹ ìš©</th>\n",
       "      <th>ì…íšŒê²½ê³¼ê°œì›”ìˆ˜_ì‹ ìš©</th>\n",
       "      <th>...</th>\n",
       "      <th>ë³€ë™ë¥ _í• ë¶€í‰ì”</th>\n",
       "      <th>ë³€ë™ë¥ _CAí‰ì”</th>\n",
       "      <th>ë³€ë™ë¥ _RVCAí‰ì”</th>\n",
       "      <th>ë³€ë™ë¥ _ì¹´ë“œë¡ í‰ì”</th>\n",
       "      <th>ë³€ë™ë¥ _ì”ì•¡_B1M</th>\n",
       "      <th>ë³€ë™ë¥ _ì”ì•¡_ì¼ì‹œë¶ˆ_B1M</th>\n",
       "      <th>ë³€ë™ë¥ _ì”ì•¡_CA_B1M</th>\n",
       "      <th>í˜œíƒìˆ˜í˜œìœ¨_R3M</th>\n",
       "      <th>í˜œíƒìˆ˜í˜œìœ¨_B0M</th>\n",
       "      <th>Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201807</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20130101</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>1.042805</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.261886</td>\n",
       "      <td>0.270752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.044401</td>\n",
       "      <td>1.280543</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201807</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20170801</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905663</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.563388</td>\n",
       "      <td>-0.670348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201807</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20080401</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>1.993590</td>\n",
       "      <td>0.852567</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.046516</td>\n",
       "      <td>0.058114</td>\n",
       "      <td>-0.014191</td>\n",
       "      <td>0.524159</td>\n",
       "      <td>1.208420</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201807</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20160501</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>1.050646</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.023821</td>\n",
       "      <td>0.258943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.880925</td>\n",
       "      <td>1.657124</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201807</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20180601</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 809 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ê¸°ì¤€ë…„ì›”  ë‚¨ë…€êµ¬ë¶„ì½”ë“œ  íšŒì›ì—¬ë¶€_ì´ìš©ê°€ëŠ¥  íšŒì›ì—¬ë¶€_ì´ìš©ê°€ëŠ¥_CA  íšŒì›ì—¬ë¶€_ì´ìš©ê°€ëŠ¥_ì¹´ë“œë¡   ì†Œì§€ì—¬ë¶€_ì‹ ìš©  \\\n",
       "0  201807       2          1             1              0        1   \n",
       "1  201807       1          1             1              1        1   \n",
       "2  201807       1          1             1              0        1   \n",
       "3  201807       2          1             1              0        1   \n",
       "4  201807       2          1             1              1        1   \n",
       "\n",
       "   ì†Œì§€ì¹´ë“œìˆ˜_ìœ íš¨_ì‹ ìš©  ì†Œì§€ì¹´ë“œìˆ˜_ì´ìš©ê°€ëŠ¥_ì‹ ìš©   ì…íšŒì¼ì_ì‹ ìš©  ì…íšŒê²½ê³¼ê°œì›”ìˆ˜_ì‹ ìš©  ...  ë³€ë™ë¥ _í• ë¶€í‰ì”  ë³€ë™ë¥ _CAí‰ì”  \\\n",
       "0            1              1  20130101          67  ...  1.042805  0.999700   \n",
       "1            1              1  20170801          12  ...  0.905663  0.999998   \n",
       "2            1              1  20080401         124  ...  1.993590  0.852567   \n",
       "3            2              2  20160501          27  ...  1.050646  0.999877   \n",
       "4            1              1  20180601           2  ...  0.999998  0.999998   \n",
       "\n",
       "   ë³€ë™ë¥ _RVCAí‰ì”  ë³€ë™ë¥ _ì¹´ë“œë¡ í‰ì”  ë³€ë™ë¥ _ì”ì•¡_B1M  ë³€ë™ë¥ _ì”ì•¡_ì¼ì‹œë¶ˆ_B1M  ë³€ë™ë¥ _ì”ì•¡_CA_B1M  \\\n",
       "0    0.999998   0.999998    0.261886        0.270752       0.000000   \n",
       "1    0.999998   0.999998   -0.563388       -0.670348       0.000000   \n",
       "2    0.999998   0.999998   -0.046516        0.058114      -0.014191   \n",
       "3    0.999998   0.999998    0.023821        0.258943       0.000000   \n",
       "4    0.999998   0.999998    0.000000        0.000000       0.000000   \n",
       "\n",
       "   í˜œíƒìˆ˜í˜œìœ¨_R3M  í˜œíƒìˆ˜í˜œìœ¨_B0M  Segment  \n",
       "0   1.044401   1.280543        D  \n",
       "1   0.000000   0.000000        E  \n",
       "2   0.524159   1.208420        C  \n",
       "3   0.880925   1.657124        D  \n",
       "4   0.000000   0.000000        E  \n",
       "\n",
       "[5 rows x 809 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numeric_df = pd.read_csv(\"../data/numeric_train.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature / Label ë¶„ë¦¬\n",
    "y = numeric_df[\"Segment\"]\n",
    "X = numeric_df.drop(columns=[\"Segment\"])\n",
    "\n",
    "# Label ì¸ì½”ë”©\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, stratify=y_encoded, random_state=8432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optunaNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "     -------------------------------------- 383.6/383.6 KB 8.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\ssafy\\desktop\\ê°œì¸í´ë”\\dacon\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_ai_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages (from optuna) (2.0.2)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Collecting PyYAML\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
      "     ------------------------------------- 231.8/231.8 KB 13.8 MB/s eta 0:00:00\n",
      "Collecting sqlalchemy>=1.4.2\n",
      "  Downloading sqlalchemy-2.0.40-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 19.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ssafy\\desktop\\ê°œì¸í´ë”\\dacon\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_ai_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages (from optuna) (24.2)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 KB ? eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\ssafy\\desktop\\ê°œì¸í´ë”\\dacon\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_ai_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Collecting greenlet>=1\n",
      "  Using cached greenlet-3.1.1-cp39-cp39-win_amd64.whl (298 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ssafy\\desktop\\ê°œì¸í´ë”\\dacon\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_ai_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Collecting MarkupSafe>=0.9.2\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl (15 kB)\n",
      "Installing collected packages: tqdm, PyYAML, MarkupSafe, greenlet, colorlog, sqlalchemy, Mako, alembic, optuna\n",
      "Successfully installed Mako-1.3.9 MarkupSafe-3.0.2 PyYAML-6.0.2 alembic-1.15.1 colorlog-6.9.0 greenlet-3.1.1 optuna-4.2.1 sqlalchemy-2.0.40 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "# %pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-03-28 09:10:07,554] A new study created in memory with name: no-name-4f94b1a1-78a6-4981-a917-6086f169615f\n",
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:12:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:29:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:34:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:37:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:39:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[W 2025-03-28 09:39:50,909] Trial 0 failed with parameters: {'n_estimators': 278, 'max_depth': 18, 'learning_rate': 0.06898796915923991, 'subsample': 0.9286906694853356, 'colsample_bytree': 0.71913491269502, 'gamma': 4.271796156372782, 'reg_alpha': 0.588504612425488, 'reg_lambda': 0.3697060677115236} because of the following error: ValueError('\\nAll the 5 fits failed.\\nIt is very likely that your model is misconfigured.\\nYou can try to debug the error by setting error_score=\\'raise\\'.\\n\\nBelow are more details about the failures:\\n--------------------------------------------------------------------------------\\n1 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\sklearn\\\\model_selection\\\\_validation.py\", line 866, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 726, in inner_f\\n    return func(**kwargs)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\sklearn.py\", line 1599, in fit\\n    self._Booster = train(\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 726, in inner_f\\n    return func(**kwargs)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\training.py\", line 181, in train\\n    bst.update(dtrain, iteration=i, fobj=obj)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 2100, in update\\n    _check_call(\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 284, in _check_call\\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\\nxgboost.core.XGBoostError: [09:27:42] C:\\\\buildkite-agent\\\\builds\\\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\\\xgboost\\\\xgboost-ci-windows\\\\src\\\\common\\\\io.h:320: bad_malloc: Failed to allocate 22287219120 bytes.\\n\\n--------------------------------------------------------------------------------\\n1 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\sklearn\\\\model_selection\\\\_validation.py\", line 866, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 726, in inner_f\\n    return func(**kwargs)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\sklearn.py\", line 1599, in fit\\n    self._Booster = train(\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 726, in inner_f\\n    return func(**kwargs)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\training.py\", line 181, in train\\n    bst.update(dtrain, iteration=i, fobj=obj)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 2100, in update\\n    _check_call(\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 284, in _check_call\\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\\nxgboost.core.XGBoostError: [09:33:03] C:\\\\buildkite-agent\\\\builds\\\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\\\xgboost\\\\xgboost-ci-windows\\\\src\\\\common\\\\io.h:320: bad_malloc: Failed to allocate 17425304496 bytes.\\n\\n--------------------------------------------------------------------------------\\n1 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\sklearn\\\\model_selection\\\\_validation.py\", line 866, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 726, in inner_f\\n    return func(**kwargs)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\sklearn.py\", line 1599, in fit\\n    self._Booster = train(\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 726, in inner_f\\n    return func(**kwargs)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\training.py\", line 181, in train\\n    bst.update(dtrain, iteration=i, fobj=obj)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 2100, in update\\n    _check_call(\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 284, in _check_call\\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\\nxgboost.core.XGBoostError: [09:36:31] C:\\\\buildkite-agent\\\\builds\\\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\\\xgboost\\\\xgboost-ci-windows\\\\src\\\\common\\\\io.h:320: bad_malloc: Failed to allocate 13293422848 bytes.\\n\\n--------------------------------------------------------------------------------\\n1 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\sklearn\\\\model_selection\\\\_validation.py\", line 866, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 726, in inner_f\\n    return func(**kwargs)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\sklearn.py\", line 1599, in fit\\n    self._Booster = train(\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 726, in inner_f\\n    return func(**kwargs)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\training.py\", line 181, in train\\n    bst.update(dtrain, iteration=i, fobj=obj)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 2100, in update\\n    _check_call(\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 284, in _check_call\\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\\nxgboost.core.XGBoostError: [09:38:15] C:\\\\buildkite-agent\\\\builds\\\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\\\xgboost\\\\xgboost-ci-windows\\\\src\\\\common\\\\io.h:320: bad_malloc: Failed to allocate 7612601344 bytes.\\n\\n--------------------------------------------------------------------------------\\n1 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\sklearn\\\\model_selection\\\\_validation.py\", line 866, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 726, in inner_f\\n    return func(**kwargs)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\sklearn.py\", line 1599, in fit\\n    self._Booster = train(\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 726, in inner_f\\n    return func(**kwargs)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\training.py\", line 181, in train\\n    bst.update(dtrain, iteration=i, fobj=obj)\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 2100, in update\\n    _check_call(\\n  File \"c:\\\\Users\\\\SSAFY\\\\Desktop\\\\ê°œì¸í´ë”\\\\DACON\\\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\\\venv\\\\lib\\\\site-packages\\\\xgboost\\\\core.py\", line 284, in _check_call\\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\\nxgboost.core.XGBoostError: [09:39:50] C:\\\\buildkite-agent\\\\builds\\\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\\\xgboost\\\\xgboost-ci-windows\\\\src\\\\common\\\\io.h:320: bad_malloc: Failed to allocate 2942967600 bytes.\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\SSAFY\\AppData\\Local\\Temp\\ipykernel_13648\\3305469614.py\", line 22, in objective\n",
      "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 684, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 431, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 517, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [09:27:42] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 22287219120 bytes.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [09:33:03] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 17425304496 bytes.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [09:36:31] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 13293422848 bytes.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [09:38:15] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 7612601344 bytes.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [09:39:50] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 2942967600 bytes.\n",
      "\n",
      "[W 2025-03-28 09:39:50,948] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n    self._Booster = train(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n    bst.update(dtrain, iteration=i, fobj=obj)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n    _check_call(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [09:27:42] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 22287219120 bytes.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n    self._Booster = train(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n    bst.update(dtrain, iteration=i, fobj=obj)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n    _check_call(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [09:33:03] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 17425304496 bytes.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n    self._Booster = train(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n    bst.update(dtrain, iteration=i, fobj=obj)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n    _check_call(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [09:36:31] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 13293422848 bytes.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n    self._Booster = train(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n    bst.update(dtrain, iteration=i, fobj=obj)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n    _check_call(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [09:38:15] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 7612601344 bytes.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n    self._Booster = train(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n    bst.update(dtrain, iteration=i, fobj=obj)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n    _check_call(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [09:39:50] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 2942967600 bytes.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Optuna íŠœë‹ ìˆ˜í–‰\u001b[39;00m\n\u001b[0;32m     26\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# ìµœì  íŒŒë¼ë¯¸í„° í™•ì¸\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[9], line 22\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      8\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m500\u001b[39m),\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m20\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_metric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     19\u001b[0m }\n\u001b[0;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m---> 22\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[1;32mc:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:431\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    411\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    412\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    413\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    429\u001b[0m )\n\u001b[1;32m--> 431\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    516\u001b[0m     )\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n    self._Booster = train(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n    bst.update(dtrain, iteration=i, fobj=obj)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n    _check_call(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [09:27:42] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 22287219120 bytes.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n    self._Booster = train(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n    bst.update(dtrain, iteration=i, fobj=obj)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n    _check_call(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [09:33:03] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 17425304496 bytes.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n    self._Booster = train(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n    bst.update(dtrain, iteration=i, fobj=obj)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n    _check_call(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [09:36:31] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 13293422848 bytes.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n    self._Booster = train(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n    bst.update(dtrain, iteration=i, fobj=obj)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n    _check_call(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [09:38:15] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 7612601344 bytes.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1599, in fit\n    self._Booster = train(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n    bst.update(dtrain, iteration=i, fobj=obj)\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2100, in update\n    _check_call(\n  File \"c:\\Users\\SSAFY\\Desktop\\ê°œì¸í´ë”\\DACON\\01_ì‹ ìš©ì¹´ë“œ_ê³ ê°_ì„¸ê·¸ë¨¼íŠ¸_ë¶„ë¥˜_AI_ê²½ì§„ëŒ€íšŒ\\venv\\lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [09:39:50] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\common\\io.h:320: bad_malloc: Failed to allocate 2942967600 bytes.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Optuna ëª©ì  í•¨ìˆ˜ ì •ì˜\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 20),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# Optuna íŠœë‹ ìˆ˜í–‰\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# ìµœì  íŒŒë¼ë¯¸í„° í™•ì¸\n",
    "print(\"Best trial:\")\n",
    "print(f\"  Value: {study.best_trial.value}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€\n",
    "best_params = study.best_trial.params\n",
    "best_params['use_label_encoder'] = False\n",
    "best_params['eval_metric'] = 'logloss'\n",
    "\n",
    "model = XGBClassifier(**best_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (Missing Values Handling)\n",
    "- í‰ê· , ì¤‘ì•™ê°’, ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "- íŠ¹ì • ê°’ìœ¼ë¡œ ëŒ€ì²´ (ì˜ˆ: -1, 0, ê¸°íƒ€ ì˜ë¯¸ ìˆëŠ” ê°’)\n",
    "- ë³´ê°„(interpolation)ì„ í†µí•œ ëˆ„ë½ê°’ ì±„ìš°ê¸°\n",
    "- KNN ë˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì¶”ì •ì„ ì´ìš©í•œ ì±„ìš°ê¸°\n",
    "- ê²°ì¸¡ì¹˜ê°€ ë§ì€ í”¼ì²˜ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 2. ì´ìƒì¹˜ ì²˜ë¦¬ (Outlier Treatment)\n",
    "- í†µê³„ì  ë°©ë²• (IQR, Z-score)ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€ ë° ì œê±°\n",
    "- ìœˆì €ë¼ì´ì§•(Winsorizing): ê·¹ë‹¨ê°’ì„ ìµœëŒ€ ë˜ëŠ” ìµœì†Œê°’ìœ¼ë¡œ ì œí•œ\n",
    "- ì´ìƒì¹˜ë¥¼ ë³„ë„ í”¼ì²˜ë¡œ ìƒì„±í•˜ì—¬ í‘œí˜„ (ì´ì§„ í”Œë˜ê·¸ í˜•íƒœ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 3. ì¸ì½”ë”© (Encoding Categorical Variables)\n",
    "- ì›-í•« ì¸ì½”ë”©(One-Hot Encoding)\n",
    "- ë¼ë²¨ ì¸ì½”ë”©(Label Encoding)\n",
    "- ë¹ˆë„ ê¸°ë°˜ ì¸ì½”ë”©(Frequency Encoding)\n",
    "- ìˆœì„œ ì¸ì½”ë”©(Ordinal Encoding)\n",
    "- íƒ€ê¹ƒ ì¸ì½”ë”©(Target Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 4. í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ ë° ì •ê·œí™” (Scaling and Normalization)\n",
    "- ìµœì†Œ-ìµœëŒ€ ì •ê·œí™”(Min-Max Scaling)\n",
    "- í‘œì¤€í™”(Standardization, Z-score Scaling)\n",
    "- ë¡œê·¸(log), ë°•ìŠ¤-ì½•ìŠ¤(Box-Cox), ì—¬(Yeo)-ì¡´ìŠ¨ ë³€í™˜ ë“±\n",
    "- ë¡œë²„ìŠ¤íŠ¸ ìŠ¤ì¼€ì¼ë§(Robust Scaling, ì´ìƒì¹˜ ì¡´ì¬ ì‹œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 5. í”¼ì²˜ ìƒì„± (Feature Creation)\n",
    "- ì‚°ìˆ  ì—°ì‚°(ë§ì…ˆ, ëº„ì…ˆ, ê³±ì…ˆ, ë‚˜ëˆ—ì…ˆ)ì„ í†µí•œ ìƒˆë¡œìš´ í”¼ì²˜ ìƒì„±\n",
    "- ë‹¤í•­ì‹ íŠ¹ì„±(Polynomial Features)\n",
    "- ë„ë©”ì¸ ê¸°ë°˜ íŒŒìƒë³€ìˆ˜ ìƒì„± (ì˜ˆ: BMI = ëª¸ë¬´ê²Œ/í‚¤Â²)\n",
    "- ë‚ ì§œ/ì‹œê°„ ê¸°ë°˜ íŒŒìƒë³€ìˆ˜ (ìš”ì¼, ì£¼ë§ ì—¬ë¶€, ê³„ì ˆ ë“±)\n",
    "- ìƒí˜¸ì‘ìš©(interaction) íŠ¹ì„± ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 6. í”¼ì²˜ ì¶”ì¶œ (Feature Extraction)\n",
    "- PCA (Principal Component Analysis, ì£¼ì„±ë¶„ ë¶„ì„)\n",
    "- SVD (Singular Value Decomposition, íŠ¹ì´ê°’ ë¶„í•´)\n",
    "- t-SNE, UMAP ë“± ì°¨ì› ì¶•ì†Œ ê¸°ë²•\n",
    "- í´ëŸ¬ìŠ¤í„°ë§ ê¸°ë°˜ í”¼ì²˜ ìƒì„± (ì˜ˆ: êµ°ì§‘ ID)\n",
    "- AutoEncoderë¥¼ í†µí•œ íŠ¹ì„± ì¶”ì¶œ (ë”¥ëŸ¬ë‹ ë°©ì‹)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 7. í”¼ì²˜ ì„ íƒ (Feature Selection)\n",
    "- ìƒê´€ê´€ê³„ ë¶„ì„ì„ í†µí•œ ë‹¤ì¤‘ê³µì„ ì„± ì œê±°\n",
    "- í”¼ì²˜ ì¤‘ìš”ë„ ê¸°ë°˜ ì„ íƒ (ëœë¤í¬ë ˆìŠ¤íŠ¸, XGBoost, LightGBM ë“±)\n",
    "- ì¬ê·€ì  í”¼ì²˜ ì œê±° (Recursive Feature Elimination, RFE)\n",
    "- í†µê³„ì  í…ŒìŠ¤íŠ¸ ê¸°ë°˜ í”¼ì²˜ ì„ íƒ (ANOVA, Chi-square test ë“±)\n",
    "- Wrapper ë°©ë²• (ëª¨ë¸ ê¸°ë°˜ íƒìƒ‰ì  í”¼ì²˜ ì„ íƒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 8. ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ (Handling Imbalanced Data)\n",
    "- ì˜¤ë²„ìƒ˜í”Œë§(Oversampling): SMOTE ë° ë³€í˜•(SMOTE-Tomek ë“±)\n",
    "- ì–¸ë”ìƒ˜í”Œë§(Undersampling): Random, Tomek Links, Edited Nearest Neighbor\n",
    "- í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜(Class Weight) ì ìš©\n",
    "- ë°ì´í„° ì¦ê°•(Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 9. ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬ (Time-Series Data Processing)\n",
    "- ì´ë™ í‰ê· (Moving average), ì§€ìˆ˜í‰í™œ(Exponential smoothing) ë“±ì˜ ì‹œê³„ì—´ í”¼ì²˜ ìƒì„±\n",
    "- ì‹œê°„ì°¨(lag) ë³€ìˆ˜ ìƒì„±\n",
    "- ë¡¤ë§ ìœˆë„ìš°(rolling window)ë¥¼ ì´ìš©í•œ íŠ¹ì„± ì¶”ì¶œ\n",
    "- ì£¼ê¸°ì„± ë° ê³„ì ˆì„± íŒ¨í„´ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 10. ì§€ë¦¬ì  ë°ì´í„° ì²˜ë¦¬ (Geospatial Data Processing)\n",
    "- ì¢Œí‘œ ë³€í™˜(ìœ„ë„, ê²½ë„ â†’ ê±°ë¦¬, ë°©í–¥ ë“±)\n",
    "- Geohash ë˜ëŠ” ì§€ë„ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§\n",
    "- ì§€ë¦¬ì  ì¸ì ‘ì„±ì„ ì´ìš©í•œ í”¼ì²˜ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
