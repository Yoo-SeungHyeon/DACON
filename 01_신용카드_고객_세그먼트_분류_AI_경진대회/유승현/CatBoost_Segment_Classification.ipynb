{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\udcca CatBoost Segment Classification Pipeline\n", "This notebook includes:\n", "- SPA (Sequential Feature Selection) on numerical features\n", "- CatBoost model training\n", "- Optuna hyperparameter tuning\n", "- Final prediction for test dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udce6 Imports\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.model_selection import train_test_split, StratifiedKFold\n", "from sklearn.feature_selection import SequentialFeatureSelector\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import f1_score\n", "from catboost import CatBoostClassifier\n", "import optuna"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udcc2 Load Data\n", "X_all = pd.read_csv(\"train.csv\").drop(columns=[\"segment\"])\n", "y_all = pd.read_csv(\"train.csv\")[\"segment\"]\n", "X_final_test = pd.read_csv(\"test.csv\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udd27 Define numeric and categorical columns\n", "numeric_columns = [col for col in X_all.columns if \"num_\" in col]  # customize this\n", "categorical_columns = [col for col in X_all.columns if col not in numeric_columns]\n", "\n", "X_train, X_val, y_train, y_val = train_test_split(\n", "    X_all, y_all, test_size=0.2, stratify=y_all, random_state=42\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udcc9 Apply SPA (Sequential Feature Selection) on numeric columns\n", "selector = SequentialFeatureSelector(RandomForestClassifier(n_estimators=100),\n", "                                     n_features_to_select=100, direction='backward', n_jobs=-1)\n", "selector.fit(X_train[numeric_columns], y_train)\n", "\n", "selected_numeric_columns = X_train[numeric_columns].columns[selector.get_support()]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83e\uddea Rebuild training/validation/test sets\n", "X_train_selected = pd.concat([X_train[selected_numeric_columns], X_train[categorical_columns]], axis=1)\n", "X_val_selected = pd.concat([X_val[selected_numeric_columns], X_val[categorical_columns]], axis=1)\n", "X_test_selected = pd.concat([X_final_test[selected_numeric_columns], X_final_test[categorical_columns]], axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2696\ufe0f Compute class weights\n", "from sklearn.utils.class_weight import compute_class_weight\n", "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n", "class_weights = dict(zip(np.unique(y_train), class_weights))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83e\uddea Optuna Tuning\n", "cat_features_idx = [X_train_selected.columns.get_loc(col) for col in categorical_columns]\n", "\n", "def objective(trial):\n", "    params = {\n", "        \"iterations\": trial.suggest_int(\"iterations\", 300, 1000),\n", "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n", "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n", "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-2, 10.0, log=True),\n", "        \"random_strength\": trial.suggest_float(\"random_strength\", 1e-3, 1.0, log=True),\n", "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n", "        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n", "        \"loss_function\": \"MultiClass\",\n", "        \"verbose\": 0,\n", "        \"cat_features\": cat_features_idx,\n", "        \"class_weights\": class_weights\n", "    }\n", "    model = CatBoostClassifier(**params)\n", "    model.fit(X_train_selected, y_train)\n", "    preds = model.predict(X_val_selected)\n", "    return f1_score(y_val, preds, average='macro')\n", "\n", "study = optuna.create_study(direction=\"maximize\")\n", "study.optimize(objective, n_trials=50)\n", "\n", "print(\"Best Parameters:\", study.best_params)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\ude80 Final model training on all data\n", "X_total = pd.concat([X_all[selected_numeric_columns], X_all[categorical_columns]], axis=1)\n", "final_model = CatBoostClassifier(\n", "    **study.best_params,\n", "    loss_function='MultiClass',\n", "    cat_features=cat_features_idx,\n", "    class_weights=class_weights,\n", "    verbose=100\n", ")\n", "final_model.fit(X_total, y_all)\n", "\n", "# Predict on final test set\n", "preds_test = final_model.predict(X_test_selected)\n", "\n", "# Save submission\n", "submission = pd.DataFrame({\"id\": X_final_test[\"id\"], \"segment\": preds_test.ravel()})\n", "submission.to_csv(\"submission.csv\", index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 2}