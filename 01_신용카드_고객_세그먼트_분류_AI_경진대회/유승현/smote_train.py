import gc
import time
import joblib
import pandas as pd
from xgboost import XGBClassifier
from sklearn.metrics import f1_score, classification_report
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline  # âœ… íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train_df = pd.read_csv("../data/important_train.csv")

# 2. Feature / Label ë¶„ë¦¬
y = train_df["Segment"]
X = train_df.drop(columns=["Segment"])

# 3. Label ì¸ì½”ë”©
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# 4. ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 5. ì¸ì½”ë” ë° ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
joblib.dump(label_encoder, "label_encoder2.joblib")
joblib.dump(scaler, "scaler2.joblib")
print("âœ… label_encoder ë° scaler ì €ì¥ ì™„ë£Œ")

# 6. Train/Test ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_encoded, test_size=0.2, stratify=y_encoded, random_state=8432
)

# âœ… 7. ì˜¤ë²„ìƒ˜í”Œë§ + ì–¸ë”ìƒ˜í”Œë§ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
# print("ğŸ” SMOTE + RandomUnderSampler ì ìš© ì¤‘...")

# resampling_pipeline = Pipeline([
#     ('smote', SMOTE(random_state=42)),
#     ('under', RandomUnderSampler(random_state=42))
# ])

# X_train_res, y_train_res = resampling_pipeline.fit_resample(X_train, y_train)
# print(f"âœ… ìƒ˜í”Œë§ ì™„ë£Œ. í•™ìŠµ ë°ì´í„° shape: {X_train_res.shape}, í´ë˜ìŠ¤ ë¶„í¬: {pd.Series(y_train_res).value_counts().to_dict()}")

# 8. XGBoost í•™ìŠµ
depth_values = [6, 7, 8, 9, 10, 11, 12, 13]

for depth in depth_values:
    print(f"\nğŸŒ² XGBoost max_depth={depth}") 
    model = XGBClassifier(max_depth=depth, use_label_encoder=False, eval_metric='mlogloss', random_state=42)
    
    start_time = time.time()
    model.fit(X_train_res, y_train_res)
    y_pred = model.predict(X_test)
    elapsed_time = time.time() - start_time

    f1 = f1_score(y_test, y_pred, average='macro')
    print(f"ğŸ” F1_macro score: {f1:.4f}")
    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))
    print(f"â± í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")

    # ëª¨ë¸ ì €ì¥
    model_filename = f"xgboost2_depth{depth}_f1{f1:.4f}.joblib"
    joblib.dump(model, model_filename)
    print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_filename}")

    # ë©”ëª¨ë¦¬ í•´ì œ
    del model
    gc.collect()
